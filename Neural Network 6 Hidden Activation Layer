import numpy as np 
import nnfs
from nnfs.datasets import spiral_data

nnfs.init()




class Layer_Dense:
    def __init__(self,n_inputs_shape) -> None:
        self.weights = 0.10 * np.random.randn(n_inputs_shape[0],n_inputs_shape[1])
        self.biases  = np.zeros((1,n_inputs_shape[1]))
    def forward(self,inputs):
        self.outputs = np.dot(inputs,self.weights)+ self.biases


# Rectified Linear activation function
class Activation_ReLU:
    def forward(self,inputs):
        self.outputs = np.maximum(0,inputs)


class Activation_Softmax:
    def forward(self,inputs):
        # we need subtract max value of array from array value so the exp value will be between 0 to 1 only 
        exp_output = np.exp(inputs - np.max(inputs,axis = 1,keepdims=True))
        sum_exp_output = np.sum(exp_output,axis = 1,keepdims=True)
        self.output= exp_output/sum_exp_output


X,y = spiral_data(100,3)
print(X.shape)
layer_dense1 = Layer_Dense((2,3))
relu_layer1 = Activation_ReLU()

layer_dense2 =Layer_Dense((3,3))
softmax_layer2 = Activation_Softmax()


layer_dense1.forward(X)
relu_layer1.forward(layer_dense1.outputs)
layer_dense2.forward(relu_layer1.outputs)
softmax_layer2.forward(layer_dense2.outputs)
print(softmax_layer2.output)

